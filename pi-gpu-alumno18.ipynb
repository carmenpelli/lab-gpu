{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1c8780-2f8d-4998-8988-28904ce89d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Default (desde Jupyter)\n",
    "#N = 5 * 10**6\n",
    "N = 10**7\n",
    "# Si viene por línea de comandos\n",
    "try:\n",
    "    N = int(sys.argv[1])\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5e385",
   "metadata": {},
   "source": [
    "### Serial version with numpy w/ arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de873fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000\n",
      "float32\n",
      "\n",
      " \t Computing pi with numpy: \n",
      "\n",
      "19.2 ms ± 17 μs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
      "\t For 10000000 trials, pi = 3.141469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def calc_pi_numpy(a, b):\n",
    "    # 2. Calculate the squared distance from the origin for all points\n",
    "    # This calculation (a**2 + b**2) is vectorized, \n",
    "    # meaning it's applied to all N elements simultaneously.\n",
    "    dist_sq = a**2 + b**2\n",
    "    \n",
    "    # 3. Count the \"hits\" inside the circle\n",
    "    # (dist_sq < 1.0) creates a boolean array (e.g., [True, False, True...])\n",
    "    # np.sum() efficiently counts the True values (since True=1, False=0).\n",
    "    M = np.sum(dist_sq < 1.0)\n",
    "    \n",
    "    # 4. Return the standard Monte Carlo estimate for pi\n",
    "    return 4 * M / N\n",
    "    \n",
    "print(N)\n",
    "#N = int(sys.argv[1])\n",
    "\n",
    "# 1. Generate all N random coordinates at once\n",
    "# Creates two arrays, x and y, each with N random numbers from -1 to 1\n",
    "x = np.random.uniform(-1, 1, N).astype(np.float32)\n",
    "y = np.random.uniform(-1, 1, N).astype(np.float32)\n",
    "print(x.dtype)\n",
    "\n",
    "pi = calc_pi_numpy(x,y)\n",
    "\n",
    "print(\"\\n \\t Computing pi with numpy: \\n\")\n",
    "%timeit -r3 calc_pi_numpy(x,y)\n",
    "print(\"\\t For %d trials, pi = %f\\n\" % (N,pi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521bd816-66df-447f-96bb-e68b305accb4",
   "metadata": {},
   "source": [
    "### Cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff1316a-eae2-42b9-a6b2-d6bfd1ee9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \t Computing pi with CuPy:\n",
      "\n",
      "11.1 ms ± 20.8 μs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
      "\t For 10000000 trials, pi = 3.141097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "def calc_pi_cupy(x, y):\n",
    "    # Copiamos datos a GPU\n",
    "    xg = cp.asarray(x)\n",
    "    yg = cp.asarray(y)\n",
    "\n",
    "    # Cálculo en GPU\n",
    "    dist_sq = xg*xg + yg*yg\n",
    "    M = cp.sum(dist_sq < 1.0)\n",
    "\n",
    "    # Traemos solo el escalar a CPU\n",
    "    return 4.0 * float(M.get()) / N\n",
    "\n",
    "\n",
    "print(\"\\n \\t Computing pi with CuPy:\\n\")\n",
    "\n",
    "# Warm-up (obligatorio)\n",
    "_ = calc_pi_cupy(x, y)\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "# Medición REAL del tiempo\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "%timeit -r3 calc_pi_cupy(x, y)\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "pi_cupy = calc_pi_cupy(x, y)\n",
    "print(\"\\t For %d trials, pi = %f\\n\" % (N, pi_cupy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670fbda-584a-4333-ab47-6062b914b2f8",
   "metadata": {},
   "source": [
    "### Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4688a765-602a-47b4-9fa9-d8f6f457b182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \t Computing pi with Numba GPU: \n",
      "\n",
      "20.1 ms ± 582 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "\t For 10000000 trials, pi = 3.141469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "# Numba ufunc on GPU\n",
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def inside_circle_numba(x, y):\n",
    "    if x*x + y*y < 1.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def calc_pi_numba(x, y, N):\n",
    "    # GPU: compute 0/1 array\n",
    "    hits = inside_circle_numba(x, y)\n",
    "\n",
    "    # CPU: reduction (as required by the statement)\n",
    "    M = np.sum(hits)\n",
    "\n",
    "    return 4.0 * M / N\n",
    "\n",
    "# First call (includes JIT compilation)\n",
    "pi_numba = calc_pi_numba(x, y, N)\n",
    "\n",
    "print(\"\\n \\t Computing pi with Numba GPU: \\n\")\n",
    "%timeit -r3 calc_pi_numba(x, y, N)\n",
    "print(\"\\t For %d trials, pi = %f\\n\" % (N, pi_numba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd24ab8-9b9b-4a8e-8e46-bbb190d3d139",
   "metadata": {},
   "source": [
    "### Selida ejecución en Bohr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f8e3c-be23-4a59-b80c-1684d1223fc6",
   "metadata": {},
   "source": [
    "### 10^7\n",
    "10000000\n",
    "float32\n",
    "\n",
    " \t Computing pi with numpy: \n",
    "\n",
    "18.1 ms ± 2.66 μs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
    "\t For 10000000 trials, pi = 3.141621\n",
    "\n",
    "\n",
    " \t Computing pi with CuPy:\n",
    "\n",
    "9.13 ms ± 15.5 μs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
    "\t For 10000000 trials, pi = 3.141621\n",
    "\n",
    "\n",
    " \t Computing pi with Numba GPU: \n",
    "\n",
    "17.1 ms ± 38.5 μs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
    "\t For 10000000 trials, pi = 3.141621\n",
    "     \n",
    "### 10^8\n",
    "100000000\n",
    "float32\n",
    "\n",
    " \t Computing pi with numpy: \n",
    "\n",
    "188 ms ± 63.4 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
    "\t For 100000000 trials, pi = 3.141642\n",
    "\n",
    "\n",
    " \t Computing pi with CuPy:\n",
    "\n",
    "91.7 ms ± 3.29 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
    "\t For 100000000 trials, pi = 3.141642\n",
    "\n",
    "\n",
    " \t Computing pi with Numba GPU: \n",
    "\n",
    "154 ms ± 476 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
    "\t For 100000000 trials, pi = 3.141640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deb4546-a5f4-4bbe-b695-dc95e00cc204",
   "metadata": {},
   "source": [
    "## Análisis de resultados\n",
    "\n",
    "Los resultados muestran que la versión con **NumPy en CPU** presenta un tiempo de ejecución que crece aproximadamente de forma lineal con el número de puntos N, como es esperable al tratarse de un cálculo vectorizado pero ejecutado únicamente en CPU.\n",
    "\n",
    "El uso de **CuPy** permite aprovechar directamente la GPU, obteniéndose una reducción significativa del tiempo de ejecución respecto a NumPy, especialmente para valores grandes de N. Esto se debe a que tanto el cálculo vectorizado como la reducción se realizan completamente en la GPU, minimizando la transferencia de datos entre CPU y GPU.\n",
    "\n",
    "La versión con **Numba utilizando @vectorize(target='cuda')** también permite ejecutar el cálculo en la GPU, pero en este caso el rendimiento es algo inferior al de CuPy (la reducción se realiza fuera del kernel). Aun así, el uso de Numba mejora los tiempos respecto a la versión puramente en CPU.\n",
    "\n",
    "En conjunto, los resultados muestran que el uso de GPU acelera de forma notable este tipo de cálculos\n",
    "científicos, siendo CuPy la opción más eficiente en este caso, mientras que Numba ofrece una alternativa\n",
    "flexible aunque con un mayor coste de ejecución."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
